{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ITCS 6162: Data Mining - Programming Assignment"
      ],
      "metadata": {
        "id": "Hr7SGYEq69wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this assignment, you will explore data analysis, recommendation algorithms, and graph-based techniques using the MovieLens dataset. Your tasks will range from basic data exploration to advanced recommendation models, including:**\n",
        "- Data manipulation with pandas\n",
        "- User-item collaborative filtering\n",
        "- Similarity-based recommendation models\n",
        "- A Pixie-inspired Graph-based recommendation using adjacency lists with weighted random walks (without using NetworkX)\n"
      ],
      "metadata": {
        "id": "L_idzFtE7M_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Dataset Files:**\n",
        "- **`u.data`**: User-movie ratings (`user_id  movie_id  rating  timestamp`)\n",
        "- **`u.item`**: Movie metadata (`movie_id | title | release date | IMDB_website`)\n",
        "- **`u.user`**: User demographics (`user_id | age | gender | occupation | zip_code`)"
      ],
      "metadata": {
        "id": "EZxjOF_l79zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1: Exploring and Cleaning Data**"
      ],
      "metadata": {
        "id": "ytr6isc2F9g6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting the Dataset Format\n",
        "\n",
        "The dataset is not in a traditional CSV format. To examine its structure, use the following shell command to display the first 10 lines of the file:\n",
        "\n",
        "```sh\n",
        "!head <file_name>\n"
      ],
      "metadata": {
        "id": "87kIrhTC9Ba1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the cells given below. Write the code to read the files.**"
      ],
      "metadata": {
        "id": "PjOtbBWM9xWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XOoSaKsq68nD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "b78cf808-dc39-4043-d826-f706d44dc9f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-01f687cd-0c7d-49ca-b423-4e211ecf087b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-01f687cd-0c7d-49ca-b423-4e211ecf087b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving u.data to u.data\n",
            "196\t242\t3\t881250949\n",
            "186\t302\t3\t891717742\n",
            "22\t377\t1\t878887116\n",
            "244\t51\t2\t880606923\n",
            "166\t346\t1\t886397596\n",
            "298\t474\t4\t884182806\n",
            "115\t265\t2\t881171488\n",
            "253\t465\t5\t891628467\n",
            "305\t451\t3\t886324817\n",
            "6\t86\t3\t883603013\n"
          ]
        }
      ],
      "source": [
        "# u.data\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!head u.data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# u.item\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!head u.item"
      ],
      "metadata": {
        "id": "dckMko0o9t-D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8ca9bfb7-30b5-4405-e16f-0f1659a1b996"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-33cd5e3d-e83d-4bf2-8d51-893d75b1b7e2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-33cd5e3d-e83d-4bf2-8d51-893d75b1b7e2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving u.item to u.item\n",
            "1|Toy Story (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)|0|0|0|1|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0\n",
            "2|GoldenEye (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?GoldenEye%20(1995)|0|1|1|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "3|Four Rooms (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995)|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|0|1|0|0\n",
            "4|Get Shorty (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995)|0|1|0|0|0|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "5|Copycat (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Copycat%20(1995)|0|0|0|0|0|0|1|0|1|0|0|0|0|0|0|0|1|0|0\n",
            "6|Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)|01-Jan-1995||http://us.imdb.com/Title?Yao+a+yao+yao+dao+waipo+qiao+(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "7|Twelve Monkeys (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Twelve%20Monkeys%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|1|0|0|0\n",
            "8|Babe (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Babe%20(1995)|0|0|0|0|1|1|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "9|Dead Man Walking (1995)|01-Jan-1995||http://us.imdb.com/M/title-exact?Dead%20Man%20Walking%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|0|0\n",
            "10|Richard III (1995)|22-Jan-1996||http://us.imdb.com/M/title-exact?Richard%20III%20(1995)|0|0|0|0|0|0|0|0|1|0|0|0|0|0|0|0|0|1|0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# u.user\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "!head u.user"
      ],
      "metadata": {
        "id": "R7kBwpsi-WKB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "dcd8b551-9191-44ac-d9d9-924fdaad830c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e19db1e-5d7a-4dde-9dac-a65aac76ab13\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1e19db1e-5d7a-4dde-9dac-a65aac76ab13\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving u.user to u.user\n",
            "1|24|M|technician|85711\n",
            "2|53|F|other|94043\n",
            "3|23|M|writer|32067\n",
            "4|24|M|technician|43537\n",
            "5|33|F|other|15213\n",
            "6|42|M|executive|98101\n",
            "7|57|M|administrator|91344\n",
            "8|36|M|administrator|05201\n",
            "9|29|M|student|01002\n",
            "10|53|M|lawyer|90703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading the Dataset with Pandas"
      ],
      "metadata": {
        "id": "YnryIHO7-db3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use **pandas** to load the dataset into a DataFrame for analysis. Follow these steps:  \n",
        "\n",
        "1. Import the necessary library: `pandas`.  \n",
        "2. Use `pd.read_csv()` (or an appropriate function) to read the dataset file.  \n",
        "3. Ensure the dataset is loaded with the correct delimiter (e.g., `','`, `'\\t'`,`'|'` , or another separator if needed).  \n",
        "4. Select and display the first few rows using `.head()`."
      ],
      "metadata": {
        "id": "Jwmza7riBj30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure that:  \n",
        "\n",
        "- The `ratings` dataset is read from `\"u.data\"` using tab (`'\\t'`) as a separator and column names (`\"user_id\"`, `\"movie_id\"`, `\"rating\"` and `\"timestamp\"`).  \n",
        "- The `movies` dataset is read from `\"u.item\"` using `'|'` as a separator, use columns (`0`, `1`, `2`), encoding (`\"latin-1\"`) and name the columns (`movie_id`, `title`, and `release_date`).  \n",
        "- The `users` dataset is read from `\"u.user\"` using `'|'` as a separator, use columns (`0`, `1`, `2`, `3`) and name the columns (`user_id`, `age`, `gender`, and `occupation`)."
      ],
      "metadata": {
        "id": "KPEDYYGOBOSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings\n",
        "import pandas as pd\n",
        "\n",
        "ratings_columns = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
        "ratings_df = pd.read_csv('u.data', sep='\\t', names=ratings_columns)\n",
        "\n",
        "print(\"Ratings Data:\")\n",
        "print(ratings_df.head())"
      ],
      "metadata": {
        "id": "Go-Y-Ofy-ZTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962ff90d-6049-4d89-9086-b6ae9802e0d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings Data:\n",
            "   user_id  movie_id  rating  timestamp\n",
            "0      196       242       3  881250949\n",
            "1      186       302       3  891717742\n",
            "2       22       377       1  878887116\n",
            "3      244        51       2  880606923\n",
            "4      166       346       1  886397596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# movies\n",
        "movies_columns = ['movie_id', 'title', 'release_date']\n",
        "movies_df = pd.read_csv(\n",
        "    'u.item',\n",
        "    sep='|',\n",
        "    usecols=[0, 1, 2],\n",
        "    names=movies_columns,\n",
        "    encoding='latin-1'\n",
        ")\n",
        "\n",
        "print(\"Movies Data:\")\n",
        "print(movies_df.head())"
      ],
      "metadata": {
        "id": "zM8IJGh-CLN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fd07311-d1be-45a5-96e1-dd077642cabb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies Data:\n",
            "   movie_id              title release_date\n",
            "0         1   Toy Story (1995)  01-Jan-1995\n",
            "1         2   GoldenEye (1995)  01-Jan-1995\n",
            "2         3  Four Rooms (1995)  01-Jan-1995\n",
            "3         4  Get Shorty (1995)  01-Jan-1995\n",
            "4         5     Copycat (1995)  01-Jan-1995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# users\n",
        "users_columns = ['user_id', 'age', 'gender', 'occupation']\n",
        "users_df = pd.read_csv(\n",
        "    'u.user',\n",
        "    sep='|',\n",
        "    usecols=[0, 1, 2, 3],\n",
        "    names=users_columns\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ‘¤ Users Data:\")\n",
        "print(users_df.head())"
      ],
      "metadata": {
        "id": "hsekVjevCNKj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30169207-009a-4228-d54d-ead1ce93f9ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ‘¤ Users Data:\n",
            "   user_id  age gender  occupation\n",
            "0        1   24      M  technician\n",
            "1        2   53      F       other\n",
            "2        3   23      M      writer\n",
            "3        4   24      M  technician\n",
            "4        5   33      F       other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** As a **Bonus** task save the `ratings`, `movies` and `users` dataframe created into a `.csv` file format. <br>\n",
        "**Hint:** Use the `to_csv()` function in pandas to save these DataFrames as CSV files."
      ],
      "metadata": {
        "id": "jE5OHLqt7xeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings\n",
        "ratings_df.to_csv('ratings.csv', index=False)\n",
        "print(\"ratings saved!\")"
      ],
      "metadata": {
        "id": "Chyv3c4n8wVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f93c98-2f1e-4b4d-a958-e797777b43d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ratings saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# movies\n",
        "movies_df.to_csv('movies.csv', index=False)\n",
        "print(\"movies saved!\")"
      ],
      "metadata": {
        "id": "Gl7zVV3y8wKU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055ebf88-4ed1-4baa-c7b7-b52ff90bc29d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movies saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# users\n",
        "users_df.to_csv('users.csv', index=False)\n",
        "print(\"users saved!\")"
      ],
      "metadata": {
        "id": "0YwVuebp8u46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4db2281f-fa6e-4985-d6d5-fc8b5be2077a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "users saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the first 10 rows of each file.**"
      ],
      "metadata": {
        "id": "s3S1y82cCYxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings\n",
        "print(\"1st 10 rows of ratings data:\")\n",
        "print(ratings_df.head(10))"
      ],
      "metadata": {
        "id": "x5ZOXTqnCPgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f914d69b-d0bf-43fa-b0b5-1c465d4db149"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st 10 rows of ratings data:\n",
            "   user_id  movie_id  rating  timestamp\n",
            "0      196       242       3  881250949\n",
            "1      186       302       3  891717742\n",
            "2       22       377       1  878887116\n",
            "3      244        51       2  880606923\n",
            "4      166       346       1  886397596\n",
            "5      298       474       4  884182806\n",
            "6      115       265       2  881171488\n",
            "7      253       465       5  891628467\n",
            "8      305       451       3  886324817\n",
            "9        6        86       3  883603013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# movies\n",
        "print(\"1st 10 rows of movie data:\")\n",
        "print(movies_df.head(10))"
      ],
      "metadata": {
        "id": "AzuqiRkrCdfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6294007-6ae9-413e-b546-4299dc39b21e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st 10 rows of movie data:\n",
            "   movie_id                                              title release_date\n",
            "0         1                                   Toy Story (1995)  01-Jan-1995\n",
            "1         2                                   GoldenEye (1995)  01-Jan-1995\n",
            "2         3                                  Four Rooms (1995)  01-Jan-1995\n",
            "3         4                                  Get Shorty (1995)  01-Jan-1995\n",
            "4         5                                     Copycat (1995)  01-Jan-1995\n",
            "5         6  Shanghai Triad (Yao a yao yao dao waipo qiao) ...  01-Jan-1995\n",
            "6         7                              Twelve Monkeys (1995)  01-Jan-1995\n",
            "7         8                                        Babe (1995)  01-Jan-1995\n",
            "8         9                            Dead Man Walking (1995)  01-Jan-1995\n",
            "9        10                                 Richard III (1995)  22-Jan-1996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# users\n",
        "print(\"1st 10 rows of user data:\")\n",
        "print(users_df.head(10))"
      ],
      "metadata": {
        "id": "FE9hcM9mCewe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab6e3cf-c0b1-41f5-c62b-73d271a2ad78"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st 10 rows of user data:\n",
            "   user_id  age gender     occupation\n",
            "0        1   24      M     technician\n",
            "1        2   53      F          other\n",
            "2        3   23      M         writer\n",
            "3        4   24      M     technician\n",
            "4        5   33      F          other\n",
            "5        6   42      M      executive\n",
            "6        7   57      M  administrator\n",
            "7        8   36      M  administrator\n",
            "8        9   29      M        student\n",
            "9       10   53      M         lawyer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning and Exploration with Pandas  \n",
        "\n",
        "After loading the dataset, itâ€™s important to clean and explore the data to ensure consistency and accuracy. Below are key **pandas** functions for cleaning and understanding the dataset.\n",
        "\n",
        "#### 1. Handle Missing Values  \n",
        "- `df.dropna()` â€“ Removes rows with missing values.  \n",
        "- `df.fillna(value)` â€“ Fills missing values with a specified value.  \n",
        "\n",
        "#### 2. Remove Duplicates  \n",
        "- `df.drop_duplicates()` â€“ Drops duplicate rows from the dataset.  \n",
        "\n",
        "#### 3. Handle Incorrect Data Types  \n",
        "- `df.astype(dtype)` â€“ Converts columns to the appropriate data type.  \n",
        "\n",
        "#### 4. Filter Outliers (if applicable)  \n",
        "- `df[df['column_name'] > threshold]` â€“ Filters rows based on a condition.  \n",
        "\n",
        "#### 5. Rename Columns (if needed)  \n",
        "- `df.rename(columns={'old_name': 'new_name'})` â€“ Renames columns for clarity.  \n",
        "\n",
        "#### 6. Reset Index  \n",
        "- `df.reset_index(drop=True, inplace=True)` â€“ Resets the index after cleaning.  \n",
        "\n",
        "### Data Exploration Functions  \n",
        "\n",
        "To better understand the dataset, use these **pandas** functions:  \n",
        "\n",
        "- `df.shape` â€“ Returns the number of rows and columns in the dataset.  \n",
        "- `df.nunique()` â€“ Displays the number of unique values in each column.  \n",
        "- `df['column_name'].unique()` â€“ Returns unique values in a specific column.  \n",
        "\n",
        "**Example Usage in Pandas:**  \n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"your_file.csv\")\n",
        "\n",
        "# Drop missing values\n",
        "df_cleaned = df.dropna()\n",
        "\n",
        "# Remove duplicate rows\n",
        "df_cleaned = df_cleaned.drop_duplicates()\n",
        "\n",
        "# Convert 'timestamp' column to datetime format\n",
        "df_cleaned['timestamp'] = pd.to_datetime(df_cleaned['timestamp'])\n",
        "\n",
        "# Display dataset shape\n",
        "print(\"Dataset shape:\", df_cleaned.shape)\n",
        "\n",
        "# Display number of unique values in each column\n",
        "print(\"Unique values per column:\\n\", df_cleaned.nunique())\n",
        "\n",
        "# Display unique movie IDs\n",
        "print(\"Unique movie IDs:\", df_cleaned['movie_id'].unique()[:10])  # Show first 10 unique movie IDs\n"
      ],
      "metadata": {
        "id": "i38iDIz-DiVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** The functions mentioned above are some of the widely used **pandas** functions for data cleaning and exploration. However, it is not necessary that all of these functions will be required in the exercises below. Use them as needed based on the dataset and the specific tasks."
      ],
      "metadata": {
        "id": "4cwmLON4EItA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert Timestamps into Readable dates.**"
      ],
      "metadata": {
        "id": "Tn0bLOSACxMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings\n",
        "ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
        "\n",
        "print(\"ratings w/ readable dates:\")\n",
        "print(ratings_df.head(10))"
      ],
      "metadata": {
        "id": "9MwnDxeeCf8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302331bb-40da-45f8-c053-9c351bfc02de"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ratings w/ readable dates:\n",
            "   user_id  movie_id  rating           timestamp\n",
            "0      196       242       3 1997-12-04 15:55:49\n",
            "1      186       302       3 1998-04-04 19:22:22\n",
            "2       22       377       1 1997-11-07 07:18:36\n",
            "3      244        51       2 1997-11-27 05:02:03\n",
            "4      166       346       1 1998-02-02 05:33:16\n",
            "5      298       474       4 1998-01-07 14:20:06\n",
            "6      115       265       2 1997-12-03 17:51:28\n",
            "7      253       465       5 1998-04-03 18:34:27\n",
            "8      305       451       3 1998-02-01 09:20:17\n",
            "9        6        86       3 1997-12-31 21:16:53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check for Missing Values**"
      ],
      "metadata": {
        "id": "oKJB0a9CE0Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings\n",
        "print(\"missing values in rating data:\")\n",
        "print(ratings_df.isnull().sum())"
      ],
      "metadata": {
        "id": "iYf4NM47DL7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7e5e6d-07af-4cd8-9aee-5b58cff0b8c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values in rating data:\n",
            "user_id      0\n",
            "movie_id     0\n",
            "rating       0\n",
            "timestamp    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# movies\n",
        "print(\"missing values in movie data:\")\n",
        "print(movies_df.isnull().sum())"
      ],
      "metadata": {
        "id": "hgM78fNaFH2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b66725-34ec-4e43-e77e-8595b05126fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values in movie data:\n",
            "movie_id        0\n",
            "title           0\n",
            "release_date    1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# users\n",
        "print(\"missing values in user data:\")\n",
        "print(users_df.isnull().sum())"
      ],
      "metadata": {
        "id": "jE8J_cajFA5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4355c5b-d6d0-400c-8de0-d640ef7ce6ee"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values in user data:\n",
            "user_id       0\n",
            "age           0\n",
            "gender        0\n",
            "occupation    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Print the total number of users, movies, and ratings.**"
      ],
      "metadata": {
        "id": "1WviFe7iFRoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total Users: {users_df['user_id'].nunique()}\")\n",
        "print(f\"Total Movies: {movies_df['movie_id'].nunique()}\")\n",
        "print(f\"Total Ratings: {len(ratings_df)}\")"
      ],
      "metadata": {
        "id": "eR_QgS9aFTPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa717dd-7cb8-4036-cf4c-9abe59b04a35"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Users: 943\n",
            "Total Movies: 1682\n",
            "Total Ratings: 100000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 2: Collaborative Filtering-Based Recommendation**"
      ],
      "metadata": {
        "id": "NjxACjUgFwsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create a User-Item Matrix**"
      ],
      "metadata": {
        "id": "AyeSaLpRGYuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Instructions for Creating a User-Movie Rating Matrix"
      ],
      "metadata": {
        "id": "3tKsv-7XHRq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, you will create a user-movie rating matrix using **pandas**. This matrix will represent the ratings that users have given to different movies.\n",
        "\n",
        "1. **Dataset Overview**:  \n",
        "   The dataset has already been loaded. It includes the following key columns:\n",
        "   - `user_id`: The ID of the user.\n",
        "   - `movie_id`: The ID of the movie.\n",
        "   - `ratings`: The rating the user gave to the movie.\n",
        "\n",
        "2. **Create the User-Movie Rating Matrix**:  \n",
        "   Use the **`pivot()`** function in **pandas** to reshape the data. Your goal is to create a matrix where:\n",
        "   - Each **row** represents a **user**.\n",
        "   - Each **column** represents a **movie**.\n",
        "   - Each **cell** contains the **rating** that the user has given to the movie.\n",
        "\n",
        "   Specify the following parameters for the `pivot()` function:\n",
        "   - **`index`**: The `user_id` column (this will define the rows).\n",
        "   - **`columns`**: The `movie_id` column (this will define the columns).\n",
        "   - **`values`**: The `rating` column (this will fill the matrix with ratings).\n",
        "\n",
        "3. **Inspect the Matrix**:  \n",
        "   After creating the matrix, examine the first few rows of the resulting matrix to ensure it has been constructed correctly.\n",
        "\n",
        "4. **Handle Missing Values**:  \n",
        "   It's likely that some users have not rated every movie, resulting in `NaN` values in the matrix. You will need to handle these missing values. Consider the following options:\n",
        "   - **Fill with 0**: If you wish to represent missing ratings as zeros (indicating no rating).\n",
        "   - **Fill with the average rating**: Alternatively, replace missing values with the average rating for each movie."
      ],
      "metadata": {
        "id": "lLayr0YbH4tB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create the user-movie rating matrix using the `pivot()` function.**"
      ],
      "metadata": {
        "id": "E_cdPXYeaD-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_movie_matrix = ratings_df.pivot(index='user_id', columns='movie_id', values='rating')\n",
        "print(user_movie_matrix.head())"
      ],
      "metadata": {
        "id": "Ie858yKEUSfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedad29a-6004-486a-84c3-e38e9b90a2ef"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
            "user_id                                                               ...   \n",
            "1          5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
            "2          4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
            "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
            "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
            "5          4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
            "\n",
            "movie_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
            "user_id                                                               \n",
            "1          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "2          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "5          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "\n",
            "[5 rows x 1682 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display the matrix to verify the transformation.**"
      ],
      "metadata": {
        "id": "tyb3h9FmaVGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"user-movie rating matrix:\")\n",
        "print(user_movie_matrix.head(10))"
      ],
      "metadata": {
        "id": "16abaOrXabN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b9bc98-ab4b-4976-86d2-514bfd70b4fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user-movie rating matrix:\n",
            "movie_id  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
            "user_id                                                               ...   \n",
            "1          5.0   3.0   4.0   3.0   3.0   5.0   4.0   1.0   5.0   3.0  ...   \n",
            "2          4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   2.0  ...   \n",
            "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
            "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
            "5          4.0   3.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
            "6          4.0   NaN   NaN   NaN   NaN   NaN   2.0   4.0   4.0   NaN  ...   \n",
            "7          NaN   NaN   NaN   5.0   NaN   NaN   5.0   5.0   5.0   4.0  ...   \n",
            "8          NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN  ...   \n",
            "9          NaN   NaN   NaN   NaN   NaN   5.0   4.0   NaN   NaN   NaN  ...   \n",
            "10         4.0   NaN   NaN   4.0   NaN   NaN   4.0   NaN   4.0   NaN  ...   \n",
            "\n",
            "movie_id  1673  1674  1675  1676  1677  1678  1679  1680  1681  1682  \n",
            "user_id                                                               \n",
            "1          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "2          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "5          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "6          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "7          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "8          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "9          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "10         NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
            "\n",
            "[10 rows x 1682 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **User-Based Collaborative Filtering Recommender System**"
      ],
      "metadata": {
        "id": "fOXp00QSbtHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Objective**\n",
        "In this task, you will implement a **user-based collaborative filtering** movie recommendation system using the **Movie dataset**. The goal is to recommend movies to a user based on the preferences of similar users."
      ],
      "metadata": {
        "id": "FwKBZk5Sc7YA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 1: Import Required Libraries**\n",
        "Before starting, ensure you have the necessary libraries installed. Use the following imports:\n",
        "\n",
        "```python\n",
        "import pandas as pd  # For handling data\n",
        "import numpy as np   # For numerical computations\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # For computing user similarity\n",
        "```"
      ],
      "metadata": {
        "id": "fZf-Nu2rdPHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 2: Compute User-User Similarity**\n",
        "- We will use **cosine similarity** to measure how similar each pair of users is based on their movie ratings.\n",
        "- Since `cosine_similarity` does not handle missing values (NaN), replace them with `0` before computation."
      ],
      "metadata": {
        "id": "qzJNshMbdwyR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Instructions:**\n",
        "1. Fill missing values with `0` using `.fillna(0)`.\n",
        "2. Compute similarity using `cosine_similarity()`.\n",
        "3. Convert the result into a **Pandas DataFrame**, with users as both row and column labels.\n",
        "\n",
        "##### **Hint:**  \n",
        "You can achieve this using the following approach:\n",
        "\n",
        "```python\n",
        "user_similarity = cosine_similarity(user_movie_matrix.fillna(0))\n",
        "user_sim_df = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
        "```"
      ],
      "metadata": {
        "id": "pkO_XtPqd4Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 3: Implement the Recommendation Function**\n",
        "Now, implement the function `recommend_movies_for_user(user_id, num=5)` to recommend movies for a given user.\n",
        "\n",
        "##### **Function Inputs:**\n",
        "- `user_id`: The target user for whom we need recommendations.\n",
        "- `num`: The number of movies to recommend (default is 5).\n",
        "\n",
        "##### **Function Steps:**\n",
        "1. Find **similar users**:\n",
        "   - Retrieve the similarity scores for the given `user_id`.\n",
        "   - Sort them in **descending** order (highest similarity first).\n",
        "   - Exclude the user themselves.\n",
        "   \n",
        "2. Get the **movie ratings** from these similar users.\n",
        "\n",
        "3. Compute the **average rating** for each movie based on these users' preferences.\n",
        "\n",
        "4. Sort the movies in **descending order** based on the computed average ratings.\n",
        "\n",
        "5. Retrieve the **top `num` recommended movies**.\n",
        "\n",
        "6. Map **movie IDs** to their **titles** using the `movies` DataFrame.\n",
        "\n",
        "7. Return the results as a **Pandas DataFrame** with rankings."
      ],
      "metadata": {
        "id": "NtmluaSGeBE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 4: Return the Final Recommendation List**\n",
        "Your function should return a **DataFrame** structured as follows:\n",
        "\n",
        "| Ranking | Movie Name |\n",
        "|---------|-----------|\n",
        "| 1       | Movie A   |\n",
        "| 2       | Movie B   |\n",
        "| 3       | Movie C   |\n",
        "| 4       | Movie D   |\n",
        "| 5       | Movie E   |\n",
        "\n",
        "##### **Hint:** Your final DataFrame should be created like this:\n",
        "```python\n",
        "result_df = pd.DataFrame({\n",
        "    'Ranking': range(1, num+1),\n",
        "    'Movie Name': movie_names     \n",
        "})\n",
        "result_df.set_index('Ranking', inplace=True)\n",
        "```\n",
        "\n",
        "#### **Example: User-Based Collaborative Filtering**\n",
        "```python\n",
        "recommend_movies_for_user(10, num = 5)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "| Ranking | Movie Name                     |\n",
        "|---------|--------------------------------|\n",
        "| 1       | In the Company of Men (1997)   |\n",
        "| 2       | MisÃ©rables, Les (1995)         |\n",
        "| 3       | Thin Blue Line, The (1988)     |\n",
        "| 4       | Braindead (1992)               |\n",
        "| 5       | Boys, Les (1997)               |\n"
      ],
      "metadata": {
        "id": "SgO0zd8LeGJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code the function here\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#Since cosine_similarity does not handle missing values (NaN), replace them with 0 before computation.\n",
        "user_movie_matrix_filled = user_movie_matrix.fillna(0)\n",
        "\n",
        "#compute cosine similarity between users\n",
        "user_similarity_matrix = cosine_similarity(user_movie_matrix_filled)\n",
        "\n",
        "#convert the result into dataframe to make it easier to read\n",
        "user_similarity_df = pd.DataFrame(user_similarity_matrix, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
        "\n",
        "#function to recommend movies for a user\n",
        "def recommend_movies_for_user(user_id, num=5):\n",
        "\n",
        "    if user_id not in user_movie_matrix.index:\n",
        "        return f\"User {user_id} not found in the dataset.\"\n",
        "\n",
        "    #retrieve similarity scores for user\n",
        "    user_similarity_scores = user_similarity_df[user_id]\n",
        "\n",
        "    #set similarity to -1 to exclude the user themselveds\n",
        "    user_similarity_scores[user_id] = -1\n",
        "\n",
        "    #get the most similar users\n",
        "    most_similar_users = user_similarity_scores.sort_values(ascending=False).index\n",
        "\n",
        "    #get the ratings from the most similar users\n",
        "    similar_users_ratings = user_movie_matrix.loc[most_similar_users]\n",
        "\n",
        "    #calculate the avg rating for each movie\n",
        "    avg_ratings = similar_users_ratings.mean(axis=0)\n",
        "\n",
        "    #sort movies by avg ratings\n",
        "    top_movies = avg_ratings.sort_values(ascending=False).head(num)\n",
        "\n",
        "    #map movie IDs to their titles\n",
        "    recommended_movie_titles = movies_df[movies_df['movie_id'].isin(top_movies.index)]['title'].values\n",
        "\n",
        "    #create the raking dataframe\n",
        "    result_df = pd.DataFrame({\n",
        "        'Ranking': range(1, num+1),\n",
        "        'Movie Name': recommended_movie_titles\n",
        "    })\n",
        "\n",
        "    result_df.set_index('Ranking', inplace=True)\n",
        "\n",
        "    return result_df\n",
        "\n",
        "print(recommend_movies_for_user(10, num=5))\n",
        "\n"
      ],
      "metadata": {
        "id": "rbENugJ5cUpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e7f79f-791f-4d29-dbd2-cff176ed1b80"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Movie Name\n",
            "Ranking                                                   \n",
            "1                                       Prefontaine (1997)\n",
            "2               Marlene Dietrich: Shadow and Light (1996) \n",
            "3                                          Star Kid (1997)\n",
            "4                                Santa with Muscles (1996)\n",
            "5        Entertaining Angels: The Dorothy Day Story (1996)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Item-Based Collaborative Filtering Recommender System**"
      ],
      "metadata": {
        "id": "MIN3XqC0eUAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Objective**\n",
        "In this task, you will implement an **item-based collaborative filtering** recommendation system using the **Movie dataset**. The goal is to recommend movies similar to a given movie based on user rating patterns."
      ],
      "metadata": {
        "id": "ytqWK-4ze2aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 1: Import Required Libraries**\n",
        "Although we have done this part already in the previous task but just to emphasize the importance reiterrating this part.\n",
        "\n",
        "Before starting, ensure you have the necessary libraries installed. Use the following imports:\n",
        "\n",
        "```python\n",
        "import pandas as pd  # For handling data\n",
        "import numpy as np   # For numerical computations\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # For computing item similarity\n",
        "```"
      ],
      "metadata": {
        "id": "Q0-HuDvffY57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2: Compute Item-Item Similarity**\n",
        "- We will use **cosine similarity** to measure how similar each pair of movies is based on their user ratings.\n",
        "- Since `cosine_similarity` does not handle missing values (NaN), replace them with `0` before computation.\n",
        "- Unlike user-based filtering, we need to **transpose** (`.T`) the `user_movie_matrix` because we want similarity between movies (columns) instead of users (rows).\n",
        "\n",
        "##### **Instructions:**\n",
        "1. Transpose the user-movie matrix using `.T` to make movies the rows.\n",
        "2. Fill missing values with `0` using `.fillna(0)`.\n",
        "3. Compute similarity using `cosine_similarity()`.\n",
        "4. Convert the result into a **Pandas DataFrame**, with movies as both row and column labels.\n",
        "\n",
        "##### **Hint:**  \n",
        "You can achieve this using the following approach:\n",
        "\n",
        "```python\n",
        "item_similarity = cosine_similarity(user_movie_matrix.T.fillna(0))\n",
        "item_sim_df = pd.DataFrame(item_similarity, index=user_movie_matrix.columns, columns=user_movie_matrix.columns)\n",
        "```"
      ],
      "metadata": {
        "id": "b9oy7pojf19r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3: Implement the Recommendation Function**\n",
        "Now, implement the function `recommend_movies(movie_name, num=5)` to recommend movies similar to a given movie.\n",
        "\n",
        "##### **Function Inputs:**\n",
        "- `movie_name`: The target movie for which we need recommendations.\n",
        "- `num`: The number of similar movies to recommend (default is 5).\n",
        "\n",
        "##### **Function Steps:**\n",
        "1. Find the **movie_id** corresponding to the given `movie_name` in the `movies` DataFrame.\n",
        "2. If the movie is not found, return an appropriate message.\n",
        "3. Extract the **similarity scores** for this movie from `item_sim_df`.\n",
        "4. Sort the movies in **descending order** based on similarity (excluding the movie itself).\n",
        "5. Retrieve the **top `num` similar movies**.\n",
        "6. Map **movie IDs** to their **titles** using the `movies` DataFrame.\n",
        "7. Return the results as a **Pandas DataFrame** with rankings."
      ],
      "metadata": {
        "id": "L8k80idUgDWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 4: Return the Final Recommendation List**\n",
        "Your function should return a **DataFrame** structured as follows:\n",
        "\n",
        "| Ranking | Movie Name |\n",
        "|---------|-----------|\n",
        "| 1       | Movie A   |\n",
        "| 2       | Movie B   |\n",
        "| 3       | Movie C   |\n",
        "| 4       | Movie D   |\n",
        "| 5       | Movie E   |\n",
        "\n",
        "##### **Hint:** Your final DataFrame should be created like this:\n",
        "```python\n",
        "result_df = pd.DataFrame({\n",
        "    'ranking': range(1, num+1),\n",
        "    'movie_name': movie_names\n",
        "})\n",
        "result_df.set_index('ranking', inplace=True)\n",
        "```"
      ],
      "metadata": {
        "id": "kNRZQWQkgLPf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Example: Item-Based Collaborative Filtering**\n",
        "```python\n",
        "recommend_movies(\"Jurassic Park (1993)\", num=5)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "| Ranking | Movie Name                               |\n",
        "|---------|------------------------------------------|\n",
        "| 1       | Top Gun (1986)                           |\n",
        "| 2       | Empire Strikes Back, The (1980)          |\n",
        "| 3       | Raiders of the Lost Ark (1981)           |\n",
        "| 4       | Indiana Jones and the Last Crusade (1989)|\n",
        "| 5       | Speed (1994)                             |\n"
      ],
      "metadata": {
        "id": "h-EEF0Q1gd9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code the function here\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#compute item similarity matrix using cosine similarity\n",
        "item_similarity = cosine_similarity(user_movie_matrix.T.fillna(0))\n",
        "\n",
        "#create a dataframe from the similarity matrix\n",
        "item_sim_df = pd.DataFrame(item_similarity, index=user_movie_matrix.columns, columns=user_movie_matrix.columns)\n",
        "\n",
        "#verify similarity matrix\n",
        "print(item_sim_df.head())\n",
        "\n",
        "def recommend_movies(movie_name, num=5):\n",
        "    movie_id = movies_df[movies_df['title'] == movie_name].movie_id\n",
        "\n",
        "    if movie_id.empty:\n",
        "        return f\"Movie '{movie_name}' not found in the dataset.\"\n",
        "\n",
        "    movie_id = movie_id.values[0]\n",
        "\n",
        "    #extract similarity scores from item_sim_df\n",
        "    movie_similarity_scores = item_sim_df[movie_id]\n",
        "\n",
        "    #sort the movies by similarity\n",
        "    movie_similarity_scores = movie_similarity_scores.sort_values(ascending=False)\n",
        "    movie_similarity_scores = movie_similarity_scores.drop(movie_id)\n",
        "\n",
        "    #get top # most similar movies\n",
        "    top_movies = movie_similarity_scores.head(num)\n",
        "\n",
        "    #map movie IDs to their titles\n",
        "    recommended_movie_titles = movies_df[movies_df['movie_id'].isin(top_movies.index)]['title'].values\n",
        "\n",
        "    # create the ranking dataframe\n",
        "    result_df = pd.DataFrame({\n",
        "        'Ranking': range(1, num+1),\n",
        "        'Movie Name': recommended_movie_titles\n",
        "    })\n",
        "\n",
        "    result_df.set_index('Ranking', inplace=True)\n",
        "\n",
        "    return result_df\n",
        "\n",
        "print(recommend_movies(\"Jurassic Park (1993)\", num=5))"
      ],
      "metadata": {
        "id": "l1K79akTebWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2e91d3-7036-435d-9da5-2841893db854"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movie_id      1         2         3         4         5         6     \\\n",
            "movie_id                                                               \n",
            "1         1.000000  0.402382  0.330245  0.454938  0.286714  0.116344   \n",
            "2         0.402382  1.000000  0.273069  0.502571  0.318836  0.083563   \n",
            "3         0.330245  0.273069  1.000000  0.324866  0.212957  0.106722   \n",
            "4         0.454938  0.502571  0.324866  1.000000  0.334239  0.090308   \n",
            "5         0.286714  0.318836  0.212957  0.334239  1.000000  0.037299   \n",
            "\n",
            "movie_id      7         8         9         10    ...      1673  1674  \\\n",
            "movie_id                                          ...                   \n",
            "1         0.620979  0.481114  0.496288  0.273935  ...  0.035387   0.0   \n",
            "2         0.383403  0.337002  0.255252  0.171082  ...  0.000000   0.0   \n",
            "3         0.372921  0.200794  0.273669  0.158104  ...  0.000000   0.0   \n",
            "4         0.489283  0.490236  0.419044  0.252561  ...  0.000000   0.0   \n",
            "5         0.334769  0.259161  0.272448  0.055453  ...  0.000000   0.0   \n",
            "\n",
            "movie_id      1675      1676      1677  1678  1679  1680      1681      1682  \n",
            "movie_id                                                                      \n",
            "1         0.000000  0.000000  0.035387   0.0   0.0   0.0  0.047183  0.047183  \n",
            "2         0.000000  0.000000  0.000000   0.0   0.0   0.0  0.078299  0.078299  \n",
            "3         0.000000  0.000000  0.032292   0.0   0.0   0.0  0.000000  0.096875  \n",
            "4         0.094022  0.094022  0.037609   0.0   0.0   0.0  0.056413  0.075218  \n",
            "5         0.000000  0.000000  0.000000   0.0   0.0   0.0  0.000000  0.094211  \n",
            "\n",
            "[5 rows x 1682 columns]\n",
            "                                        Movie Name\n",
            "Ranking                                           \n",
            "1                                   Top Gun (1986)\n",
            "2                  Empire Strikes Back, The (1980)\n",
            "3                   Raiders of the Lost Ark (1981)\n",
            "4        Indiana Jones and the Last Crusade (1989)\n",
            "5                                     Speed (1994)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 3: Graph-Based Recommender (Pixie-Inspired Algorithm)**"
      ],
      "metadata": {
        "id": "YhZXLz7Rh_VC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Adjacency List**"
      ],
      "metadata": {
        "id": "u_YceL18lWlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Objective**\n",
        "In this task, you will preprocess the Movie dataset and construct a **graph representation** where:\n",
        "- **Users** are connected to the movies they have rated.\n",
        "- **Movies** are connected to users who have rated them.\n",
        "  \n",
        "This graph structure will help in exploring **user-movie relationships** for recommendations."
      ],
      "metadata": {
        "id": "CFF1tUDsipIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 1: Merge Ratings with Movie Titles**\n",
        "Since we have **movie IDs** in the ratings dataset but need human-readable movie titles, we will:\n",
        "1. Merge the `ratings` DataFrame with the `movies` DataFrame using the `'movie_id'` column.\n",
        "2. This allows each rating to be associated with a **movie title**.\n",
        "\n",
        "#### **Hint:**\n",
        "Use the following Pandas operation to merge:\n",
        "```python\n",
        "ratings = ratings.merge(movies, on='movie_id')\n",
        "```"
      ],
      "metadata": {
        "id": "-3OPInjhkUzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### **Step 2: Aggregate Ratings**\n",
        "Since multiple users may rate the same movie multiple times, we:\n",
        "1. Group the dataset by `['user_id', 'movie_id', 'title']`.\n",
        "2. Compute the **mean rating** for each movie by each user.\n",
        "3. Reset the index to ensure we maintain a clean DataFrame structure.\n",
        "\n",
        "#### **Hint:**  \n",
        "Use `groupby()` and `mean()` as follows:\n",
        "```python\n",
        "ratings = ratings.groupby(['user_id', 'movie_id', 'title'])['rating'].mean().reset_index()\n",
        "```"
      ],
      "metadata": {
        "id": "3OPUXyNVkfHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3: Normalize Ratings**\n",
        "Since different users have different rating biases, we normalize ratings by:\n",
        "1. **Computing each user's mean rating**.\n",
        "2. **Subtracting the mean rating** from each individual rating.\n",
        "\n",
        "#### **Instructions:**\n",
        "- Use `groupby('user_id')` to group ratings by users.\n",
        "- Apply `transform(lambda x: x - x.mean())` to adjust ratings.\n",
        "\n",
        "#### **Hint:**  \n",
        "Normalize ratings using:\n",
        "```python\n",
        "ratings['rating'] = ratings.groupby('user_id')['rating'].transform(lambda x: x - x.mean())\n",
        "```\n",
        "This ensures each userâ€™s ratings are centered around zero, making similarity calculations fairer."
      ],
      "metadata": {
        "id": "NU1fB66WkqEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 4: Construct the Graph Representation**\n",
        "We represent the user-movie interactions as an **undirected graph** using an **adjacency list**:\n",
        "- Each **user** is a node connected to movies they rated.\n",
        "- Each **movie** is a node connected to users who rated it.\n",
        "\n",
        "#### **Graph Construction Steps:**\n",
        "1. Initialize an empty dictionary `graph = {}`.\n",
        "2. Iterate through the **ratings dataset**.\n",
        "3. For each `user_id` and `movie_id` pair:\n",
        "   - Add the movie to the userâ€™s set of connections.\n",
        "   - Add the user to the movieâ€™s set of connections.\n",
        "\n",
        "#### **Hint:**  \n",
        "The following code builds the graph:\n",
        "\n",
        "```python\n",
        "graph = {}\n",
        "for _, row in ratings.iterrows():\n",
        "    user, movie = row['user_id'], row['movie_id']\n",
        "    if user not in graph:\n",
        "        graph[user] = set()\n",
        "    if movie not in graph:\n",
        "        graph[movie] = set()\n",
        "    graph[user].add(movie)\n",
        "    graph[movie].add(user)\n",
        "```\n",
        "\n",
        "This results in a **bipartite graph**, where:\n",
        "- **Users** are connected to multiple movies.\n",
        "- **Movies** are connected to multiple users."
      ],
      "metadata": {
        "id": "79NB8zIWkvWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 5: Understanding the Graph**\n",
        "- **Nodes** in the graph represent **users and movies**.\n",
        "- **Edges** exist between a user and a movie **if the user has rated the movie**.\n",
        "- This structure allows us to find **users with similar movie tastes** and **movies frequently watched together**.\n",
        "\n",
        "#### **Exploring the Graph**\n",
        "- **Find a userâ€™s rated movies:**  \n",
        "  ```python\n",
        "  user_id = 1\n",
        "  print(graph[user_id])  # Movies rated by user 1\n",
        "  ```\n",
        "\n",
        "- **Find users who rated a movie:**  \n",
        "  ```python\n",
        "  movie_id = 50\n",
        "  print(graph[movie_id])  # Users who rated movie 50\n",
        "  ```"
      ],
      "metadata": {
        "id": "wEuVgjAAk4KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code the function here\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#load user/movies\n",
        "ratings = pd.read_csv('u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "\n",
        "movies = pd.read_csv('u.item', sep='|', names=[\n",
        "    'movie_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
        "    'unknown', 'Action', 'Adventure', 'Animation', 'Children\\'s', 'Comedy',\n",
        "    'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
        "    'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'\n",
        "], encoding='latin-1')\n",
        "\n",
        "ratings = ratings.merge(movies[['movie_id', 'title']], on='movie_id')\n",
        "\n",
        "ratings = ratings.groupby(['user_id', 'movie_id', 'title'])['rating'].mean().reset_index()\n",
        "\n",
        "ratings['rating'] = ratings.groupby('user_id')['rating'].transform(lambda x: x - x.mean())\n",
        "\n",
        "graph = {}\n",
        "for _, row in ratings.iterrows():\n",
        "    user, movie = row['user_id'], row['movie_id']\n",
        "    if user not in graph:\n",
        "        graph[user] = set()\n",
        "    if movie not in graph:\n",
        "        graph[movie] = set()\n",
        "    graph[user].add(movie)\n",
        "    graph[movie].add(user)\n",
        "\n",
        "user_id = 1\n",
        "print(graph[user_id])  # Movies rated by user 1\n",
        "movie_id = 50\n",
        "print(graph[movie_id])  # Users who rated movie 50"
      ],
      "metadata": {
        "id": "b4V2aL4DiMM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cff0ec4-c1ff-40a3-d0eb-5a699f9f1404"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 279, 280, 286, 287, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 303, 305, 307, 308, 311, 312, 313, 314, 320, 322, 324, 325, 326, 327, 330, 331, 332, 336, 338, 339, 340, 343, 344, 345, 347, 348, 350, 357, 359, 360, 363, 365, 371, 374, 378, 379, 380, 381, 387, 388, 389, 390, 393, 394, 395, 396, 398, 399, 401, 402, 403, 406, 407, 411, 412, 416, 417, 419, 422, 424, 425, 429, 432, 434, 435, 438, 441, 445, 447, 450, 454, 455, 456, 457, 458, 459, 460, 463, 465, 467, 468, 470, 471, 472, 478, 479, 483, 484, 486, 487, 488, 490, 493, 494, 495, 497, 500, 503, 505, 508, 512, 514, 517, 518, 521, 523, 525, 526, 532, 533, 534, 535, 536, 537, 540, 541, 542, 545, 548, 549, 550, 552, 553, 554, 560, 561, 562, 567, 569, 576, 577, 579, 580, 582, 588, 592, 593, 597, 599, 602, 605, 606, 609, 610, 612, 613, 614, 618, 620, 621, 622, 624, 630, 632, 634, 635, 636, 637, 642, 643, 648, 649, 650, 653, 654, 655, 657, 658, 660, 661, 663, 664, 665, 669, 674, 676, 677, 678, 679, 680, 682, 684, 689, 690, 691, 692, 697, 698, 699, 701, 703, 705, 706, 708, 709, 710, 714, 715, 716, 721, 723, 726, 727, 730, 731, 733, 735, 738, 742, 744, 745, 746, 747, 748, 749, 751, 756, 757, 759, 761, 763, 764, 767, 768, 769, 770, 771, 773, 777, 779, 785, 786, 788, 789, 790, 792, 793, 794, 795, 796, 798, 800, 804, 805, 806, 807, 815, 817, 821, 822, 823, 826, 829, 830, 831, 835, 838, 839, 843, 847, 852, 854, 864, 865, 867, 868, 870, 872, 879, 880, 881, 882, 883, 885, 886, 887, 889, 890, 892, 893, 894, 895, 896, 897, 899, 901, 902, 903, 907, 910, 913, 916, 917, 918, 919, 921, 922, 923, 924, 927, 929, 930, 932, 933, 934, 935, 936, 938, 941}\n",
            "{1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 18, 20, 21, 22, 23, 25, 26, 27, 28, 30, 32, 37, 41, 42, 43, 44, 45, 46, 48, 49, 51, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 77, 79, 80, 82, 83, 85, 87, 89, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 108, 109, 113, 115, 116, 117, 119, 120, 121, 123, 124, 125, 127, 128, 130, 132, 137, 141, 144, 145, 148, 150, 151, 153, 154, 157, 158, 160, 161, 162, 169, 174, 175, 176, 177, 178, 182, 183, 184, 185, 188, 189, 192, 194, 197, 198, 200, 201, 203, 209, 210, 213, 214, 215, 216, 217, 221, 222, 227, 230, 231, 232, 233, 234, 235, 236, 239, 244, 245, 246, 247, 248, 249, 250, 251, 253, 254, 256, 257, 262, 263, 265, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 279, 280, 283, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 303, 305, 307, 308, 310, 311, 312, 313, 316, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 334, 336, 337, 339, 340, 343, 344, 345, 346, 347, 350, 352, 354, 359, 360, 361, 363, 367, 368, 369, 370, 371, 373, 374, 378, 379, 380, 381, 382, 385, 386, 387, 389, 391, 392, 393, 394, 395, 397, 398, 399, 401, 402, 403, 405, 406, 407, 409, 411, 413, 416, 417, 419, 421, 422, 424, 425, 426, 429, 430, 432, 433, 435, 436, 437, 438, 444, 445, 447, 450, 452, 453, 454, 455, 456, 457, 458, 459, 461, 463, 464, 465, 466, 467, 468, 470, 471, 472, 474, 475, 478, 479, 480, 481, 482, 483, 484, 486, 487, 488, 490, 493, 494, 495, 496, 497, 498, 499, 500, 503, 504, 505, 506, 507, 508, 509, 512, 513, 514, 516, 517, 521, 523, 524, 526, 527, 528, 530, 533, 535, 536, 537, 538, 539, 540, 541, 542, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 557, 560, 561, 562, 563, 564, 566, 567, 569, 573, 575, 576, 577, 579, 580, 581, 582, 584, 586, 588, 592, 593, 594, 595, 596, 597, 600, 601, 602, 603, 606, 608, 610, 613, 618, 619, 620, 621, 622, 623, 624, 625, 629, 630, 632, 633, 634, 637, 638, 641, 642, 643, 644, 645, 648, 649, 650, 653, 654, 655, 658, 659, 660, 661, 662, 663, 664, 665, 666, 668, 669, 671, 672, 674, 676, 678, 679, 680, 682, 684, 686, 689, 691, 693, 694, 697, 698, 699, 700, 701, 703, 704, 705, 706, 708, 709, 710, 711, 712, 714, 715, 716, 717, 719, 721, 723, 727, 730, 734, 735, 736, 738, 739, 741, 742, 744, 745, 746, 747, 748, 749, 751, 753, 756, 757, 758, 759, 760, 761, 763, 764, 765, 766, 768, 770, 771, 773, 774, 776, 779, 780, 781, 782, 785, 786, 789, 790, 791, 793, 794, 795, 796, 797, 798, 799, 800, 804, 805, 806, 807, 815, 823, 825, 826, 830, 831, 832, 833, 834, 835, 838, 839, 840, 843, 844, 846, 847, 848, 850, 851, 852, 854, 862, 864, 867, 868, 869, 870, 871, 875, 878, 879, 880, 881, 882, 883, 885, 886, 887, 889, 890, 891, 892, 893, 894, 895, 896, 897, 899, 901, 902, 903, 907, 908, 910, 913, 916, 917, 919, 921, 922, 923, 924, 929, 930, 931, 933, 934, 936, 937, 938, 940, 942, 943, 1008, 1010, 1084}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Implement Weighted Random Walks**"
      ],
      "metadata": {
        "id": "_ZE31gB7lImI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Random Walk-Based Movie Recommendation System (Weighted Pixie)**"
      ],
      "metadata": {
        "id": "yHe42rlJl9kD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Objective**\n",
        "In this task, you will implement a **random-walk-based recommendation algorithm** using the **Weighted Pixie** method. This technique uses a **user-movie bipartite graph** to recommend movies by simulating a random walk from a given user or movie."
      ],
      "metadata": {
        "id": "jyqptwreo-IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 1: Import Required Libraries**\n",
        "Make sure you have the necessary libraries:\n",
        "\n",
        "```python\n",
        "import random  # For random walks\n",
        "import pandas as pd  # For handling data\n",
        "```"
      ],
      "metadata": {
        "id": "jFgyzzdCpfzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 2: Implement the Random Walk Algorithm**\n",
        "Your task is to **simulate a random walk** from a given starting point in the **bipartite user-movie graph**.\n",
        "\n",
        "##### **Hints for Implementation**\n",
        "- Start from **either a user or a movie**.\n",
        "- At each step, **randomly move** to a connected node.\n",
        "- Keep track of **how many times each movie is visited**.\n",
        "- After completing the walk, **rank movies by visit count**."
      ],
      "metadata": {
        "id": "_FVGjhl0ppFK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 3: Implement User-Based Recommendation**\n",
        "**Hints:**\n",
        "- Check if the `user_id` exists in the `graph`.\n",
        "- Start a loop that runs for `walk_length` steps.\n",
        "- Randomly pick a **connected node** (user or movie).\n",
        "- Track how many times each **movie** is visited.\n",
        "- Sort movies by visit frequency and return the **top N**.\n",
        "\n",
        "#### **Step 4: Implement Movie-Based Recommendation**\n",
        "**Hints:**\n",
        "- Find the `movie_id` corresponding to the given `movie_name`.\n",
        "- Ensure the movie exists in the `graph`.\n",
        "- Start a random walk from that movie.\n",
        "- Follow the same **tracking and ranking** process as the user-based version.\n",
        "\n",
        "**Note:**  \n",
        "**Your task:** Implement a function `weighted_pixie_recommend(user_id, walk_length=15, num=5)` or `weighted_pixie_recommend(movie_name, walk_length=15, num=5)`.  \n",
        "**Implement either Step 3 or Step 4.**"
      ],
      "metadata": {
        "id": "E7D7Pj6trss9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 5: Running Your Recommendation System**\n",
        "Once your function is implemented, test it by calling:\n",
        "\n",
        "##### **Example: User-Based Recommendation**\n",
        "```python\n",
        "weighted_pixie_recommend(1, walk_length=15, num=5)\n",
        "```\n",
        "| Ranking | Movie Name                     |\n",
        "|---------|--------------------------------|\n",
        "| 1       | My Own Private Idaho (1991)   |\n",
        "| 2       | Aladdin (1992)                |\n",
        "| 3       | 12 Angry Men (1957)           |\n",
        "| 4       | Happy Gilmore (1996)          |\n",
        "| 5       | Copycat (1995)                |\n",
        "\n",
        "\n",
        "##### **Example: Movie-Based Recommendation**\n",
        "```python\n",
        "weighted_pixie_recommend(\"Jurassic Park (1993)\", walk_length=10, num=5)\n",
        "```\n",
        "| Ranking | Movie Name                           |\n",
        "|---------|-------------------------------------|\n",
        "| 1       | Rear Window (1954)                 |\n",
        "| 2       | Great Dictator, The (1940)         |\n",
        "| 3       | Field of Dreams (1989)             |\n",
        "| 4       | Casablanca (1942)                  |\n",
        "| 5       | Nightmare Before Christmas, The (1993) |\n"
      ],
      "metadata": {
        "id": "qxN_ibCCrCpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Step 6: Understanding the Results**\n",
        "Your function should return a **DataFrame** structured as follows:\n",
        "\n",
        "| Ranking | Movie Name |\n",
        "|---------|-----------|\n",
        "| 1       | Movie A   |\n",
        "| 2       | Movie B   |\n",
        "| 3       | Movie C   |\n",
        "| 4       | Movie D   |\n",
        "| 5       | Movie E   |\n",
        "\n",
        "Each movie is ranked based on **how frequently it was visited** during the walk.\n",
        "\n",
        "#### **Experiment with Different Parameters**\n",
        "- Try different **`walk_length`** values and observe how it changes recommendations.\n",
        "- Adjust the number of recommended movies (`num`)."
      ],
      "metadata": {
        "id": "ZpUH9IzVr5aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code the function here\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "def weighted_pixie_recommend_movie(graph, movie_name, movie_titles, walk_length=15, num=5):\n",
        "    movie_id = movie_titles.get(movie_name)\n",
        "\n",
        "    if not movie_id or movie_id not in graph:\n",
        "        return f\"Movie '{movie_name}' not found in the graph.\"\n",
        "\n",
        "    #track the num of times each movie is visited\n",
        "    movie_visit_count = {}\n",
        "\n",
        "    #start the walk from movie node\n",
        "    current_node = movie_id\n",
        "\n",
        "    for _ in range(walk_length):\n",
        "        neighbors = list(graph[current_node])\n",
        "\n",
        "        if not neighbors:\n",
        "            break\n",
        "        next_node = random.choice(neighbors)\n",
        "\n",
        "        if isinstance(next_node, int):\n",
        "            if next_node not in movie_visit_count:\n",
        "                movie_visit_count[next_node] = 0\n",
        "            movie_visit_count[next_node] += 1\n",
        "\n",
        "        current_node = next_node\n",
        "\n",
        "    #rank movies by visits\n",
        "    ranked_movies = sorted(movie_visit_count.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    #dataframe\n",
        "    result_df = pd.DataFrame(ranked_movies[:num], columns=[\"movie_id\", \"visit_count\"])\n",
        "    result_df[\"Ranking\"] = result_df.index + 1\n",
        "    result_df = result_df[[\"Ranking\", \"movie_id\", \"visit_count\"]]\n",
        "\n",
        "    return result_df\n",
        "\n",
        "movie_titles = {\n",
        "    \"Top Gun (1986)\": 101,\n",
        "    \"Empire Strikes Back, The (1980)\": 102,\n",
        "    \"Raiders of the Lost Ark (1981)\": 103\n",
        "}\n",
        "\n",
        "print(weighted_pixie_recommend_movie(graph, \"Top Gun (1986)\", movie_titles, walk_length=15, num=5))\n"
      ],
      "metadata": {
        "id": "tZD5fjG-lx3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f52e32-7fa8-4a97-b6b6-4d718eb69b99"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Ranking  movie_id  visit_count\n",
            "0        1        94            1\n",
            "1        2      1048            1\n",
            "2        3       599            1\n",
            "3        4       280            1\n",
            "4        5       672            1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Q36Y2C7PxWO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Submission Requirements:**"
      ],
      "metadata": {
        "id": "9iKlQlvBtiGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To successfully complete this assignment, ensure that you submit the following:\n",
        "\n",
        "\n",
        "### **1. Jupyter Notebook Submission**\n",
        "- Submit a **fully completed Jupyter Notebook** that includes:\n",
        "  - **All implemented recommendation functions** (user-based, item-based, and random walk-based recommendations).\n",
        "  - **Code explanations** in markdown cells to describe each step.\n",
        "  - **Results and insights** from running your recommendation models.\n",
        "\n",
        "\n",
        "### **2. Explanation of Pixie-Inspired Algorithms (3-5 Paragraphs)**\n",
        "- Write a **detailed explanation** of **Pixie-inspired random walk algorithms** used for recommendations.\n",
        "- Your explanation should cover:\n",
        "  - What **Pixie-inspired recommendation systems** are.\n",
        "  - How **random walks** help in identifying relevant recommendations.\n",
        "  - Any real-world applications of such algorithms in industry.\n",
        "\n",
        "\n",
        "### **3. Report for the Submitted Notebook**\n",
        "Your report should be structured as follows:\n",
        "\n",
        "#### **Title: Movie Recommendation System Report**\n",
        "\n",
        "#### **1. Introduction**\n",
        "- Briefly introduce **movie recommendation systems** and why they are important.\n",
        "- Explain the **different approaches used** (user-based, item-based, random-walk).\n",
        "\n",
        "#### **2. Dataset Description**\n",
        "- Describe the **MovieLens 100K dataset**:\n",
        "  - Number of users, movies, and ratings.\n",
        "  - What features were used.\n",
        "  - Any preprocessing performed.\n",
        "\n",
        "#### **3. Methodology**\n",
        "- Explain the three recommendation techniques implemented:\n",
        "  - **User-based collaborative filtering** (how user similarity was calculated).\n",
        "  - **Item-based collaborative filtering** (how item similarity was determined).\n",
        "  - **Random-walk-based Pixie algorithm** (why graph-based approaches are effective).\n",
        "  \n",
        "#### **4. Implementation Details**\n",
        "- Discuss the steps taken to build the functions.\n",
        "- Describe how the **adjacency list graph** was created.\n",
        "- Explain how **random walks** were performed and how visited movies were ranked.\n",
        "\n",
        "#### **5. Results and Evaluation**\n",
        "- Present **example outputs** from each recommendation approach.\n",
        "- Compare the different methods in terms of accuracy and usefulness.\n",
        "- Discuss any **limitations** in the implementation.\n",
        "\n",
        "#### **6. Conclusion**\n",
        "- Summarize the key takeaways from the project.\n",
        "- Discuss potential improvements (e.g., **hybrid models, additional features**).\n",
        "- Suggest real-world applications of the methods used."
      ],
      "metadata": {
        "id": "NHGGedZexPs0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Submission Instructions**"
      ],
      "metadata": {
        "id": "NWgT_Shy-vUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Submit `.zip` file consisting of Jupyter Notebook and all the datafiles (provided) and the ones saved [i.e. `users.csv`, `movies.csv` and `ratings.csv`]. Also, include the Report and Pixie Algorithm explanation document.\n",
        "- [`Bonus 10 Points`] **Upload your Jupyter Notebook, Explanation Document, and Report** to your GitHub repository.\n",
        "- Ensure the repository is public and contains:\n",
        "  - `users.csv`, `movies.csv` and `ratings.csv` [These are the Dataframes which were created in part 1. Save and export them as a `.csv` file]\n",
        "  - `Movie_Recommendation.ipynb`\n",
        "  - `Pixie_Algorithm_Explanation.pdf` or `.md`\n",
        "  - `Recommendation_Report.pdf` or `.md`\n",
        "- **Submit the GitHub repository link in the cell below.**\n",
        "\n",
        "\n",
        "#### **Example Submission Format**\n",
        "```text\n",
        "GitHub Repository: https://github.com/username/Movie-Recommendation\n",
        "```"
      ],
      "metadata": {
        "id": "Nuz1s-Vh_L55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOCUMENTAION/REPORT:\n",
        "\n",
        "Pixie-inspired systems recommend content by simulating how users explore items in a graph only made of users and items. They use random walking, where the system starts from a user or item and goes through connections to link similar or relevant items.\n",
        "\n",
        "Random walks help find items that are closely connected to the starting point in a graph. The more often an item is visited during the walk, the more likely itâ€™s relevant to the userâ€™s interests, therefor making it a good recommendation.\n",
        "\n",
        "Pinterest uses a Pixie-based system to recommend pins to users in real time. Similar techniques are also used by Netflix to suggest movies, by Amazon for product recommendations, and by different social media platforms to recommend friends or content.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "1. Introduction\n",
        "Movie recommendation systems help users find movies they might like. There are 3 main methods: user-based, item-based, and random walk.\n",
        "\n",
        "2. Dataset Description\n",
        "The MovieLens 100K dataset has 943 users, 1,682 movies, and 100,000 ratings.\n",
        "User IDs, movie IDs, and ratings were used.\n",
        "Cleaned the data and added movie titles.\n",
        "\n",
        "3. Methodology\n",
        "User-based filtering: Finds users who rate similarily to you and recommends their favorite movies.\n",
        "\n",
        "Item-based filtering: Finds movies similar to ones you rated highly.\n",
        "\n",
        "Random walk: Walks through a user-movie graph to find movies that are based on your preferences.\n",
        "\n",
        "4. Implementation Details\n",
        "Functions were created and ran for each method. A graph where users connect to the movies they rated was created then in random walks, it went from user to movie randomly and counted how often movies were visited.\n",
        "\n",
        "5. Results and Evaluation\n",
        "Random walk gave more diverse results.\n",
        "Item and user-based methods missed less popular movies.\n",
        "Limitations: didn't have timestamps or genres listed.\n",
        "\n",
        "6. Conclusion\n",
        "This was a good exercise to see how different recommendation methods work in practice. It could be improved by using hybrid models or more data.\n",
        "These methods are used in Netflix, YouTube, Pinterest, etc"
      ],
      "metadata": {
        "id": "lSSmKOD449yG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the Github Link here:\n"
      ],
      "metadata": {
        "id": "jol9nRDau6fZ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Grading Rubric: ITCS 6162 - Data Mining Assignment**"
      ],
      "metadata": {
        "id": "oQ6aluK-0ZMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| **Category**                              | **Criteria**                                                     | **Points** |\n",
        "|-------------------------------------------|----------------------------------------------------------------|------------|\n",
        "| **Part 1: Exploring and Cleaning Data (15 pts)**  | Properly loads `u.user`, `u.movies`, and `u.item` datasets into DataFrames | 5 |\n",
        "|                                           | Handles missing values, duplicates, and inconsistencies appropriately | 5 |\n",
        "|                                           | Saves the cleaned datasets into CSV files: `users.csv`, `movies.csv`, `ratings.csv` | 5 |\n",
        "| **Part 2: Collaborative Filtering-Based Recommendation (30 pts)** | Implements user-based collaborative filtering correctly | 10 |\n",
        "|                                           | Implements item-based collaborative filtering correctly | 10 |\n",
        "|                                           | Computes similarity measures accurately and provides valid recommendations | 10 |\n",
        "| **Part 3: Graph-Based Recommender (Pixie-Inspired Algorithm) (35 pts)** | Constructs adjacency lists properly from user-movie interactions | 10 |\n",
        "|                                           | Implements weighted random walk-based recommendation correctly | 15 |\n",
        "|                                           | Explains and justifies the algorithm design choices (Pixie-inspired) | 10 |\n",
        "| **Code Quality & Documentation (10 pts)** | Code is well-structured, efficient, and follows best practices | 5 |\n",
        "|                                           | Markdown explanations and comments are clear and enhance understanding | 5 |\n",
        "| **Results & Interpretation (5 pts)**      | Provides meaningful insights from the recommendation system's output | 5 |\n",
        "| **Submission & Report (5 pts)**          | Submits all required files in the correct format (ZIP file with Jupyter notebook, processed CSV files, and project report) | 5 |\n",
        "| **Total**                                 |                              | 100 |\n",
        "\n",
        "#### **Bonus (10 pts)**\n",
        "| **Category**                              | **Criteria**                                                     | **Points** |\n",
        "|-------------------------------------------|----------------------------------------------------------------|------------|\n",
        "| **GitHub Submission**                     | Provides a well-documented GitHub repository with CSV files, a structured README, and a properly formatted Jupyter Notebook | 10 |"
      ],
      "metadata": {
        "id": "sNAfeIzA_fCq"
      }
    }
  ]
}